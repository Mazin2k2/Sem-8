{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6977ec4e-7c30-4707-91bd-fa5979cfd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac498f4-f771-44f2-a2d4-304df677b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "maxlen = 200\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "# Splitting and padding sequences\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bd4bec-60ea-4059-9f8c-8995e43c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for modeling\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=16),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483fd237-c9a8-4f1f-aa13-cb7d1da5d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5315 - loss: 0.6913 - val_accuracy: 0.6616 - val_loss: 0.6799\n",
      "Epoch 2/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7041 - loss: 0.6692 - val_accuracy: 0.7450 - val_loss: 0.6271\n",
      "Epoch 3/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7736 - loss: 0.6035 - val_accuracy: 0.7783 - val_loss: 0.5436\n",
      "Epoch 4/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8100 - loss: 0.5124 - val_accuracy: 0.8252 - val_loss: 0.4633\n",
      "Epoch 5/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8376 - loss: 0.4349 - val_accuracy: 0.8395 - val_loss: 0.4049\n",
      "Epoch 6/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8631 - loss: 0.3739 - val_accuracy: 0.8515 - val_loss: 0.3684\n",
      "Epoch 7/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8763 - loss: 0.3311 - val_accuracy: 0.8607 - val_loss: 0.3442\n",
      "Epoch 8/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8797 - loss: 0.3133 - val_accuracy: 0.8630 - val_loss: 0.3311\n",
      "Epoch 9/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8891 - loss: 0.2872 - val_accuracy: 0.8686 - val_loss: 0.3175\n",
      "Epoch 10/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8966 - loss: 0.2715 - val_accuracy: 0.8714 - val_loss: 0.3100\n",
      "Epoch 11/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9040 - loss: 0.2572 - val_accuracy: 0.8698 - val_loss: 0.3044\n",
      "Epoch 12/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9082 - loss: 0.2464 - val_accuracy: 0.8758 - val_loss: 0.2976\n",
      "Epoch 13/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9123 - loss: 0.2359 - val_accuracy: 0.8779 - val_loss: 0.2935\n",
      "Epoch 14/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9165 - loss: 0.2247 - val_accuracy: 0.8763 - val_loss: 0.2919\n",
      "Epoch 15/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9214 - loss: 0.2181 - val_accuracy: 0.8792 - val_loss: 0.2895\n",
      "Training time: 20.85210347175598 seconds\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2889\n",
      "The Test Accuracy: is 0.8791599869728088\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time_training = time.time()  # Starting the timer for training\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n",
    "end_time_training = time.time()  # Ending the timer for training\n",
    "\n",
    "# Calculating and printing the time taken for training\n",
    "training_time = end_time_training - start_time_training\n",
    "print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"The Test Accuracy: is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832464b5-88d5-44da-a227-1c7706eb4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get user input\n",
    "def get_user_input():\n",
    "    review = input(\"Enter your movie review: \")\n",
    "    return review\n",
    "\n",
    "# Function to preprocess input\n",
    "def preprocess_input(review):\n",
    "    word_index = imdb.get_word_index()\n",
    "    words = review.lower().split() \n",
    "    sequence = [word_index[word] + 3 if word in word_index and word_index[word] < num_words else 2 for word in words]\n",
    "    sequence = pad_sequences([sequence], maxlen=maxlen, padding='post', truncating='post')  # Pad or truncate sequence\n",
    "    return sequence\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    start_time_prediction = time.time()  # Starting the timer for prediction\n",
    "    sequence = preprocess_input(review)\n",
    "    prediction = model.predict(sequence)[0][0]\n",
    "    end_time_prediction = time.time()  # Ending the timer for prediction\n",
    "    prediction_time = end_time_prediction - start_time_prediction  # Calculating prediction time\n",
    "    print(f\"Prediction time: {prediction_time} seconds\")  # Printing prediction time\n",
    "    return prediction\n",
    "\n",
    "# Function to plot history\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Main loop for user interaction\n",
    "while True:\n",
    "    review = get_user_input()\n",
    "    if review.lower() == 'exit':\n",
    "        break\n",
    "    prediction = predict_sentiment(review)\n",
    "    if prediction > 0.5:\n",
    "        print(\"Prediction: Positive\")\n",
    "    else:\n",
    "        print(\"Prediction: Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d2748-71ba-4861-97d6-b6e180ed9c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
