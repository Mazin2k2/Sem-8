{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6977ec4e-7c30-4707-91bd-fa5979cfd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac498f4-f771-44f2-a2d4-304df677b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "maxlen = 200\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "# Splitting and padding sequences\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bd4bec-60ea-4059-9f8c-8995e43c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for modeling\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=16),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483fd237-c9a8-4f1f-aa13-cb7d1da5d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5471 - loss: 0.6900 - val_accuracy: 0.6470 - val_loss: 0.6749\n",
      "Epoch 2/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6702 - loss: 0.6642 - val_accuracy: 0.7392 - val_loss: 0.6280\n",
      "Epoch 3/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7640 - loss: 0.6062 - val_accuracy: 0.7962 - val_loss: 0.5490\n",
      "Epoch 4/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8115 - loss: 0.5195 - val_accuracy: 0.8318 - val_loss: 0.4681\n",
      "Epoch 5/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4411 - val_accuracy: 0.8414 - val_loss: 0.4093\n",
      "Epoch 6/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8591 - loss: 0.3825 - val_accuracy: 0.8560 - val_loss: 0.3705\n",
      "Epoch 7/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8755 - loss: 0.3373 - val_accuracy: 0.8611 - val_loss: 0.3470\n",
      "Epoch 8/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8827 - loss: 0.3094 - val_accuracy: 0.8652 - val_loss: 0.3303\n",
      "Epoch 9/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8887 - loss: 0.2903 - val_accuracy: 0.8666 - val_loss: 0.3176\n",
      "Epoch 10/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8965 - loss: 0.2717 - val_accuracy: 0.8709 - val_loss: 0.3077\n",
      "Epoch 11/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9040 - loss: 0.2557 - val_accuracy: 0.8749 - val_loss: 0.3009\n",
      "Epoch 12/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9087 - loss: 0.2431 - val_accuracy: 0.8771 - val_loss: 0.2962\n",
      "Epoch 13/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9112 - loss: 0.2343 - val_accuracy: 0.8739 - val_loss: 0.2945\n",
      "Epoch 14/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9147 - loss: 0.2235 - val_accuracy: 0.8784 - val_loss: 0.2905\n",
      "Epoch 15/15\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2112 - val_accuracy: 0.8779 - val_loss: 0.2893\n",
      "Training time: 8.332563877105713 seconds\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.8782 - loss: 0.2893\n",
      "The Test Accuracy: is 0.8778799772262573\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time_training = time.time()  # Starting the timer for training\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n",
    "end_time_training = time.time()  # Ending the timer for training\n",
    "\n",
    "# Calculating and printing the time taken for training\n",
    "training_time = end_time_training - start_time_training\n",
    "print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"The Test Accuracy: is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832464b5-88d5-44da-a227-1c7706eb4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your movie review: This movie was amazing, loved every moment of it!\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Prediction time: 0.4605221748352051 seconds\n",
      "Prediction: Positive\n",
      "Enter your movie review: This movie was bad, terrible acting\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction time: 0.11036419868469238 seconds\n",
      "Prediction: Negative\n",
      "Enter your movie review: This movie was ok not bad, not good.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Prediction time: 0.11036515235900879 seconds\n",
      "Prediction: Positive\n",
      "Enter your movie review: exit\n"
     ]
    }
   ],
   "source": [
    "# Function to get user input\n",
    "def get_user_input():\n",
    "    review = input(\"Enter your movie review: \")\n",
    "    return review\n",
    "\n",
    "# Function to preprocess input\n",
    "def preprocess_input(review):\n",
    "    word_index = imdb.get_word_index()\n",
    "    words = review.lower().split() \n",
    "    sequence = [word_index[word] + 3 if word in word_index and word_index[word] < num_words else 2 for word in words]\n",
    "    sequence = pad_sequences([sequence], maxlen=maxlen, padding='post', truncating='post')  # Pad or truncate sequence\n",
    "    return sequence\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    start_time_prediction = time.time()  # Starting the timer for prediction\n",
    "    sequence = preprocess_input(review)\n",
    "    prediction = model.predict(sequence)[0][0]\n",
    "    end_time_prediction = time.time()  # Ending the timer for prediction\n",
    "    prediction_time = end_time_prediction - start_time_prediction  # Calculating prediction time\n",
    "    print(f\"Prediction time: {prediction_time} seconds\")  # Printing prediction time\n",
    "    return prediction\n",
    "\n",
    "# Function to plot history\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Main loop for user interaction\n",
    "while True:\n",
    "    review = get_user_input()\n",
    "    if review.lower() == 'exit':\n",
    "        break\n",
    "    prediction = predict_sentiment(review)\n",
    "    if prediction > 0.5:\n",
    "        print(\"Prediction: Positive\")\n",
    "    else:\n",
    "        print(\"Prediction: Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d2748-71ba-4861-97d6-b6e180ed9c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
